// vim: set syntax=asciidoc:
[[create]]
== Creating Images
:data-uri:
:toc:
:toclevels 4:
:homepage https://github.com/projectatomic/container-best-practices:

The base unit of creating an image is the Dockerfile itself.  This section
focuses on the instructions that make up a Dockerfile.

This chapter will not cover every Dockerfile instruction available but instead
will focus on specific ones that we want to re-enforce to those who develop
Dockerfiles.  Docker has published a
link:https://docs.docker.com/engine/reference/builder/[reference guide] already
covering each of the Dockerfile instructions.

=== Upstream Docker Best Practices

Upstream docker has a nice description of https://docs.docker.com/engine/articles/dockerfile_best-practices/[best practices] for Dockerfiles. It
describes the various instructions that can be used to compose a Dockerfile and their best usage.  Familiarize yourself with these
recommendations.

=== Choosing base image

Every Docker image has its own root filesystem with an operating system installed. So when you want to create a new container, it either has to be based on an image that actually provides an operating system or you will need to create this layer in your image.
There is a wide variety of base images already available on Docker Hub, so the simplest solution is to use one from there. Here are a few things that should help determine which base image will fit your needs:

* Linux distribution - Your personal preference and perhaps experience is a reason why to choose a certain distribution rather than another one. However, you should definitely consider whether your containerized application requires specific libraries from a specific system.

* Image size - The base images usually contain a minimal operating system with a set of tools needed for basic operations. To preserve your environment small and efficient, size should also be taken into account when picking the right base image. The size varies; you can take advantage of super small base images, such as 2MB busybox, or use a standard minimal operating system, such as Fedora or CentOS that are up to 200MB in size.

* Updates - Not all community images are necessarily rebuilt on a regular basis or when security vulnerabilities are addressed. You should therefore consider using base images from "official repositories" on Docker Hub, and confirm their update policy in advance.

//==== RHEL base images

==== Building your own image

===== Docker Base Image Creation

===== Minimal Operating System

// busybox

=== Creating Component or Application Images ?

=== Create small and concise images

It is preferable to create small and concise images whenever possible.  This can
be highly dependent on the application you are containerizing, but there are
techniques to help you accomplish this.  The following sections cover these
techniques.

==== Clear packaging caches and temporary package downloads

Package managers can typically generate lots of metadata and also store downloaded content into a cache of
sorts. To keep images and layers as small as possible, you should consider clearing out these caches of downloaded
content.  Note how the following example ends with a _yum -y clean all_ which removes deletable yum content.

.A singular RUN instruction performing multiple commands
```
RUN yum install -y epel-release && \
    rpmkeys --import file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 && \
    yum install -y --setopt=tsflags=nodocs bind-utils gettext iproute\
    v8314 mongodb24-mongodb mongodb24 && \
    yum -y clean all
```


==== Installing Documentation
It is generally considered good practice to keep your images as small as possible.  Above we have discussed that
package manager caches should be cleared to reduce image sizes.  You can also reduce image size by limiting the
documentation being installed.  If you package manager supports such a thing and then you have no expectations
for users to use a shell to interact with your image, this might significantly reduce the size of your image.

Yum has an optional flag to not install documentation.  The following example shows how to set the flag.
----
RUN yum install -y mysql --setopt=tsflags=nodocs
----

Note that the **nodocs** flag is used in some base images, for example CentOS and Fedora, and this setting gets inherited by the child layers. This can cause problems in case you want to include documentation deliberately in your layered image.

In this case, if you wish to have the documentation installed for **packages from your single layer only**, you have to empty the **tsflags** option as follows:

----
RUN yum -y install docker --setopt=tsflags=''
----

If you wish to have the documentation installed for **packages from your single layer and the parent layers**, you need to reinstall the packages with the empty **tsflags** option as follow:

----
RUN yum -y reinstall "*" --setopt-tsflags='' && yum install docker --setopt-tsflags=''
----

In case you need to have documentation included for **every package from every single parent or child layer**, the */etc/yum.conf* file needs to be edited as follows:

----
RUN [ -e /etc/yum.conf ] && sed -i '/tsflags=nodocs/d' /etc/yum.conf || true
RUN yum -y reinstall "*"
RUN yum -y install <package>
----


==== Updating Software supplied by Base Image

Avoid updating software supplied by base image unless necessary. Base images themselves are meant to be updated
on a regular basis by the supplier and provide software that has been tested for a particular environment.

Also, updating base-image software in layered images can introduce unexpected problems or bring in unwanted
dependencies and in certain cases significantly expand the image size.

In other words, avoid using instructions similar to this one:

```
RUN yum -y update
```

// TBD: different recommendations for Fedora and CentOS/RHEL base images?

==== Squashing layers

Each instruction you create in your Dockerfile results in a new image layer being created. Each layer brings additional data that are not always part of the resulting image. For example, if you add a file in one layer, but remove it in another layer later, the final image's size will include the added file size in a form of a special "whiteout" file although you removed it. In addition, every layer contains separate metadata that add up to the overall image size as well. So what are the benefits of squashing?

* **Performance** - since all layers are copy-on-write file systems, it will take longer to build the final container from many layers.
* **Image size ** - As already described above, any new instruction in the Dockerfile increases the overall size of the image. With squashing, you can prevent these unwanted size additions.

However, Docker does not yet support squashing natively, so you will have to work around it by using alternative approaches, some of which are listed below.

===== Chaining Commands

In general, having fewer layers improves readability. Commands that are chained together become a part of the
same layer. To reduce the number of layers, chain commands together. Find a balance, though, between a large
number of layers (and a great many commands), and a small number of layers (and obscurity caused by brevity).

A new layer is created for every new instruction defined. This does not necessarily mean that one instruction
should be associated with only one command or definition.

Ensure transparency and provide a good overview of the content of each layer by grouping related operations
together so that they together constitute a single layer. Consider this snippet from the OpenShift
Python 3.3 Dockerfile:

```
RUN yum install -y \
    https://www.softwarecollections.org/en/scls/rhscl/python33/epel-7-x86_64/download/rhscl-python33-epel-7-x86_64.noarch.rpm && \
    yum install -y --setopt=tsflags=nodocs --enablerepo=centosplus \
    python33 python33-python-devel python33-python-setuptools \
    epel-release && \
    yum install -y --setopt=tsflags=nodocs install nss_wrapper && \
    yum clean all -y && \
    scl enable python33 "easy_install pip" && \
    chown -R default:default /opt/openshift && \
    chmod -R og+rwx /opt/openshift
```

Each command that is related to the installation and configuration of `sti-python` is grouped together as a part of the same layer. This meaningful grouping of operations keeps the number of layers low while keeping the easy legibility of the layers high.

===== docker export & docker import

You can _docker export_ and _docker import_ the container to squash all the layers in your container in a single one. This approach, however, is not very practical for sharing as the user will be able to only download the whole content and cannot take advantage the caching. Note that the base image layer will be included as well and might be severl hundreds of megabytes in size.

===== Custom Tools

You will surely find a lot of utilities on the internet that facilitate layer squashing. We recommend taking advantage of Marek Goldmann's https://github.com/goldmann/docker-scripts[docker-scripts], which automates layer squashing and which is maintained and has been tested by the community.

==== Locales

=== Labels

Labels in Dockerfiles serve as a useful way to organize and document metadata used to describe an image.  Some labels are only descriptive
by nature, like  _Name_ whereas others, like _RUN_ can be used to describe action-oriented metadata.  Labels are often leveraged by applications, like
https://github.com/projectatomic/atomic[atomic], to help the image run as the author intended.  They can also for purely descriptive
purposed and can viewed manually with the _docker inspect <image_name>_ command.

The authoritative source for labels
is the  https://github.com/projectatomic/ContainerApplicationGenericLabels[Container Application Generic Labels] git repository.

==== When are they required?

==== Descriptive labels

The descriptive labels usually are alpha-numeric strings used to describe some aspect of the image itself.  Examples, might be
the version and release labels which could theoretically just be integer based.
The following table describes labels that are meant to be purely descriptive in nature.

.Descriptive labels
[options="header,footer"]
|===============================================
| Label | Description | Example
| name 	| Name of the Image | _"rhel7/rsyslog"_
| version | Version of the image | _"7.2"_
| release | Release number of the image | _"12"_
| architecture | Architecture for the image | _"x86_64"_
| build-date | Date/Time image was built as https://tools.ietf.org/html/rfc3339[RFC 3339] date-time | _"2015-12-03T10:00:44.038585Z"_
| vendor | Owner of the image | _"Red Hat, Inc."_
| URL | URL with more information about the image | _TBD_
| Summary | Brief description of the image | _TBD_
| Description | Longer description of the image | _TBD_
| vcs-type | The type of version control used by the container source. Generally one of git, hg, svn, bzr, cvs | _"git"_
| vcs-url |URL of the version control repository | _TBD_
| vcs-ref | A 'reference' within the version control repository; e.g. a git commit, or a subversion branch | _"364a...92a"_
| authoritative-source-url |	The authoritative location in which the image is published | _TBD_
| distribution-scope |Intended scope of distribution for image. Possible values are private, authoritive-source-only, restricted, or public  | _private_
| changelog-url | URL of a page containing release notes for the image| _TBD_
|===============================================

==== Action-oriented labels
[[label_action]]
Most action-oriented labels will be a used in the context of a docker command in order for the container to behave in a desired
way.  The following table describes the defined action-oriented labels.

.Action-oriented labels
[options="header,footer"]
|===============================================
| Label | Description | Example
| help | Command to run the help command of the image | _tbd_
| run | Command to run the image | _"docker run -d --privileged --name NAME --net=host --pid=host -v /etc/pki/rsyslog:/etc/pki/rsyslog -v /etc/rsyslog.conf:/etc/rsyslog.conf -v /etc/sysconfig/rsyslog:/etc/sysconfig/rsyslog -v /etc/rsyslog.d:/etc/rsyslog.d -v /var/log:/var/log -v /var/lib/rsyslog:/var/lib/rsyslog -v /run:/run -v /etc/machine-id:/etc/machine-id -v /etc/localtime:/etc/localtime -e IMAGE=IMAGE -e NAME=NAME --restart=always IMAGE /bin/rsyslog.sh"_
| uninstall | Command to uninstall the image | _"docker run --rm --privileged -v /:/host -e HOST=/host -e IMAGE=IMAGE -e NAME=NAME IMAGE /bin/uninstall.sh"_
| install |	Command to install the image | _"docker run --rm --privileged -v /:/host -e HOST=/host -e IMAGE=IMAGE -e NAME=NAME IMAGE /bin/install.sh"_
| stop | Command to execute before stopping container | _tbd_
| debug | Command to run the image with debugging turned on | _tbd_
|===============================================

==== Recommended labels for your project

Labels are critical to properly identifying your image and influencing how it runs.  For the purposes of
identification, we recommend that you at least use the following labels:

* name
* version
* release
* architecture
* vendor

And for actionable labels, we recommend you use at least the following:

* RUN
* INSTALL
* UNINSTALL

These three are the most critical for ensuring that users run the image in the manner you wish.  Furthermore,
tools developed to read and act upon this meta data will work correctly.

In the case that you provide a help file that does not follow the standard of a man page, then the HELP label would also
be prudent.

=== Template
// Should we create a default template of sorts


=== Starting your application

Generally the CMD instruction in the Dockerfile is used by docker to start your application
when the image or container is started.  In the planning section, we provided some reasoning
for choosing how to  *_xref:planning_starting_application[start your application]_*.  The following
subsections will show how to implement each choice in your Dockerfile.

==== Calling the binary directly
Being the simplest of the choices, you simply need to call the binary using the CMD instruction or
define an ENTRYPOINT in your Dockerfile.

```
CMD ["/usr/bin/some_binary"]
```

===== Using the CMD Instruction
With CMD, you can identify the default command to run from the image, along with options you want to pass to it.
If there is no ENTRYPOINT in the Dockerfile, the value of CMD is the command run by default when you start the
container image. If there is an ENTRYPOINT in the Dockerfile, the ENTRYPOINT value is run as the command instead,
with the value of CMD used as options to the ENTRYPOINT command.

The CMD instruction can be overridden when you run the image. So, notice the different results from running
mycmd in two different ways:

Any time you add an argument to the end of a docker run command, the CMD instruction inside the container is ignored.
So the second example opens a bash shell instead of running the cat command. If you want to assign a command that
is not overridden by options at the end of a docker run command, use the ENTRYPOINT instruction.

===== Using the ENTRYPOINT Instruction
Like CMD, the ENTRYPOINT instruction lets you define the command executed when you run the container image but it
cannot be overridden by arguments you put at the end of a docker run line. If your Dockerfile includes an
ENTRYPOINT instruction and there is also a CMD instruction, any arguments on the CMD instruction line are passed to
the command defined in the ENTRYPOINT line.

This is the distinct advantage of the ENTRYPOINT instruction over the CMD instruction because the command being run
is not overridden but it can be subsidized.  Suppose you have an ENTRYPOINT instruction that displays two files.
You could easily add an additional file to be displayed by adding it to the docker run command.

You can override the ENTRYPOINT command by defining a new entrypoint with the --entrypoint="" option on the docker
command line.

[[creating_using_a_script]]

==== Using a script
Using a script to start an application is very similar to calling the binary directly. Again, you
use the CMD instruction but instead of pointing at the binary you point at your script that was
injected into the image.  The _registry.access.redhat.com/rhel7/rsyslog_ image uses a script
to start the rsyslogd application. Lets look at the two relevant instructions in its Dockerfile
that make this happen.

The following instruction injects our script (rsyslog.sh) into the image in the _bin_ dir.
```
ADD rsyslog.sh /bin/rsyslog.sh
```

The contents of the script are as follows:

```
#!/bin/sh
# Wrapper to start rsyslog.d with appropriate sysconfig options

echo $$ > /var/run/syslogd.pid

source /etc/sysconfig/rsyslog
exec /usr/sbin/rsyslogd -n $SYSLOGD_OPTIONS
```

Notice how the script does in fact handle environment variables by sourcing the _/etc/sysconfig/rsyslog_
file. And the CMD instruction simply calls the script.

```
CMD [ "/bin/rsyslog.sh" ]
```

==== Using systemd

Extending our example from link:creating_using_a_script[starting an application with a script], the rsyslog
image was started with a script.  We could easily use systemd to start the application.  To use systemd
to start a service that has a unit file, we need to tell systemd to enable the service and then let the
init process handle the rest. So instead of the ADD instruction used earlier, we would use a RUN
instruction to enable the service.

```
RUN systemctl enable rsyslog
```

And then we need to change the CMD instruction to call _/usr/sbin/init_ to let systemd take over.

```
RUN /usr/sbin/init
```


// Help section
=== Creating a Help file
include::help.adoc[]


=== Creating a Changelog

=== Verifying Dockerfile (linter)






OLD - OLD - OLD - OLD - OLD - OLD - OLD - OLD - OLD - OLD - OLD - OLD - OLD - OLD - OLD - OLD - OLD - OLD -

=== Dockerfiles

==== Location

Upstream Dockerfiles should be hosted in a public GIT repository, for example https://github.com[GitHub]. Ideally, the repository should be created under the organization relevant to a particular project. For example, http://www.softwarecollections.org[Software Collections] Dockerfiles are available under the GitHub https://github.com/sclorg[sclorg] organization.

==== Images

Upstream Docker images, such as CentOS and Fedora base images and layered images based on these, should be publicly available on https://registry.hub.docker.com/[Docker Hub].

For details on using the Docker Hub registry, see https://docs.docker.com/userguide/dockerimages/[Docker User Guide].

==== Content

Docker is a platform that enables applications to be quickly assembled from components. When creating Docker images, think about the added value you can provide potential users with. The intention should always be bringing some added functionality on top of plain package installation.

As an example, take this https://github.com/docker-library/wordpress/blob/618490d4bdff6c5774b84b717979bfe3d6ba8ad1/apache/Dockerfile[Word Press Dockerfile]. After running the image and linking it with a database image such as mysql, you will get a fully operational Word Press instance. In addition, you can also specify an external database.

This exactly is the purpose of using Docker images; instead of laborious installation and configuration of separate components, you simply pull an image from a registry, acquiring a set of tools ready to be used right out-of-the-box.

==== Enabling Necessary Repositories

TBD

// maybe move somewhere RHEL-specific


==== Users
TBD

==== Working Directory
TBD

==== Exposing Ports

The +EXPOSE+ instruction declares the ports on which a container will listen for incoming connections. You should specify ports your application commonly uses; for example, as seen in this https://github.com/openshift/mysql/blob/master/5.5/Dockerfile[mysql] example:

----
EXPOSE 3306
----

IMPORTANT: The TCP/IP port numbers below 1024 are special in that normal users are not allowed to bind on them.

Therefore, for example for Apache server, ports 8080 or 8433 (HTTP or HTTPS) should be exposed. Otherwise, only the root user will be allowed to run Apache server inside a container.


// For information on exposing ports in Software Collection images, see the xref:software_collections[Software Collections] chapter.

==== Logging
TBD

...



=== References

// References to external sites and project-specific guidelines.

Please see the following resources for more information on the Docker container technology and project-specific guidelines.

http://docs.docker.com/[Docker Documentation] -- Detailed information about the Docker platform.

https://github.com/openshift/openshift-docs/blob/master/creating_images/guidelines.adoc#openshift-specific-guidelines[OpenShift Guidelines] -- Guidelines for creating images specific to the OpenShift project.
